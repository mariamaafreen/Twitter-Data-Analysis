{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c7fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0803997",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = open('/Users/sammy/Desktop/Data Challenge/data.txt','r')\n",
    "t=transcript.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf20b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good morning everyone and thanks for joining us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to start our call today by looking back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016 was a transformative year for us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformations are difficult, and this one wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We started 2016 by resetting and focusing on w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>People trust us to carry some of the most impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>We've proven now that our focus works and we n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>In doing so advances us towards our ultimate g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>I want to thank you all for your time, your su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "0      Good morning everyone and thanks for joining us\n",
       "1       I want to start our call today by looking back\n",
       "2                2016 was a transformative year for us\n",
       "3    Transformations are difficult, and this one wa...\n",
       "4    We started 2016 by resetting and focusing on w...\n",
       "..                                                 ...\n",
       "109  People trust us to carry some of the most impo...\n",
       "110  We've proven now that our focus works and we n...\n",
       "111  In doing so advances us towards our ultimate g...\n",
       "112  I want to thank you all for your time, your su...\n",
       "113                                                   \n",
       "\n",
       "[114 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_call = pd.DataFrame(t,columns=['content'])\n",
    "earnings_call  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7070bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So that led us to one of the most important areas, which is the home timeline, and making that more relevant, not just recent notifications, making those more relevant, so that we can tell people what's breaking, and what they should be, what they should direct their attention to, and easier onboarding and also easier ways to tweet\n",
      "\n",
      "We've done a lot of work across those four areas, and we're really excited that we're actually seeing that in the results as well\n",
      "\n",
      "So we organized search, moments, trends and topics into one area that you could go to after you exhaust your timeline to find new things that are happening in the world and new topics that you might be interested in and ultimately want to follow\n",
      "\n",
      "This is also an area where we can show off our live streaming games, debates, elections, and events\n",
      "\n",
      "So we're top of the funnel is one of those areas that could've benefited and we do not see a benefit to the top of the funnel from all of the activity throughout the election time period\n",
      "\n",
      "As it relates to impressions growth, which is another area we look at, as I mentioned earlier, the magnitude of the impressions of the platform is so large, it'd be very hard for an event or a single person to drive sustained growth in impressions growth\n",
      "\n",
      "In addition to that, we're focused on other revenue streams that are not ad driven, and areas of low hanging opportunity where we have audiences that aren't being monetized\n",
      "\n",
      "And the final point I'd make is what we're doing in video positions us to capture ad dollars that are not in this very competitive digital advertising bucket, and we've started to tap into those dollars through our live video product and we'll continue to invest in that area as well\n",
      "\n",
      "So the Explore tab is one area that you'll be able to go to for any live event but we're also looking at other areas that gets you to that much faster if you express an interest in a debate, for instance, or in a game or in a new show or entertainment\n",
      "\n",
      "It may have felt like we weren't changing much this past year, but those hundreds of little changes added up to more predictable and sustained growth we will now use as a foundation to be more inventive and to take bigger risks\n",
      "\n",
      "We also look at a couple of other factors to see if there's any significant changes in those trendlines\n",
      "\n",
      "That's only increased throughout 2016. In 2017, I think what we saw in mid-January, as it relates to acceleration of competitive factors, it's really when advertisers start to ramp up their spending coming out of the fourth quarter\n",
      "\n",
      "February is a time period that historically has been up 35% to 40% versus January, and that ramp really starts in mid-January through February and that's when we saw more marketplace challenges in our ability to attract demand from advertisers\n",
      "\n",
      "And as I look into 2017 and we look at what we can do, I just think the superpower we really provide the world is we can break news and get information to people faster than any other service in the world\n",
      "\n",
      "And that's why I am excited about really making sure that we apply artificial intelligence and machine learning in the right ways and that we really meet that superpower of being that little bird that told you something that you couldn't find anywhere else\n",
      "\n",
      "We have a lot of syntax that we still put in front of people and it should be as easy as just opening up your phone or the webpage and you instantly get a sense of what matters most, what people are thinking about it and how to contribute and how to participate\n",
      "\n",
      "I want to thank you all for your time, your support and we'll see you on Twitter\n",
      "\n",
      "We're thrilled to report that daily active usage accelerated for the third quarter in a row, and we see that strong growth continuing\n",
      "\n",
      "And Youssef on the leadership team, so late last year we really flattened the organization, so that we could elevate engineering product and design, so they report directly to me, so I could be a lot closer to the products\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_to_analyse = ['area','up','report']\n",
    "for i in word_to_analyse:\n",
    "    analysis = earnings_call[earnings_call['content'].str.contains(i)]\n",
    "    text_analysis = analysis['content'].values\n",
    "    for text in text_analysis:\n",
    "        print(text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4a30c55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/sammy/opt/anaconda3/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/sammy/opt/anaconda3/lib/python3.8/site-packages (from textblob) (3.6.1)\n",
      "Requirement already satisfied: click in /Users/sammy/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/sammy/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/sammy/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.59.0)\n",
      "Requirement already satisfied: regex in /Users/sammy/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2021.4.4)\n",
      "[nltk_data] Downloading package brown to /Users/sammy/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sammy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sammy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sammy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /Users/sammy/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/sammy/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n",
      "/bin/bash: -c: line 0: syntax error near unexpected token `'punkt''\n",
      "/bin/bash: -c: line 0: `nltk.download('punkt')'\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob\n",
    "!python -m textblob.download_corpora\n",
    "!nltk.download('punkt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "389c4e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.19382861290756026, subjectivity=0.47948747159273464)\n",
      "positive: 42\n",
      "negative: 3\n",
      "neutral: 8\n",
      "sentence polarity: 0.19594220227523798\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(t)):\n",
    "    t[i]=t[i]+'.'\n",
    "    \n",
    "sentiment_analysis_text = '\\n'.join(t)\n",
    "sentiment_call = TextBlob(sentiment_analysis_text)\n",
    "\n",
    "print(sentiment_call.sentiment)\n",
    "\n",
    "sentiment_call.sentences\n",
    "negative = 0\n",
    "positive = 0\n",
    "neutral = 0\n",
    "all_sentences = []\n",
    "\n",
    "for sentence in sentiment_call.sentences:\n",
    "  #print(sentence.sentiment.polarity)\n",
    "  if sentence.sentiment.polarity < 0:\n",
    "    negative +=1\n",
    "  if sentence.sentiment.polarity > 0:\n",
    "    positive += 1\n",
    "  else:\n",
    "    neutral += 1\n",
    " \n",
    "  all_sentences.append(sentence.sentiment.polarity) \n",
    "\n",
    "print('positive: ' +  str(positive))\n",
    "print('negative: ' +  str(negative))\n",
    "print('neutral: ' + str(neutral))\n",
    "\n",
    "all_sentences = np.array(all_sentences)\n",
    "print('sentence polarity: ' + str(all_sentences.mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c01b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced25ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
